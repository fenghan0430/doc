### 微调的种类

全量微调FFT(Full Fine Tuning)  
对全量的参数，进行全量的训练

PEFT(Parameter-Efficient Fine Tuning)  
只对部分的参数进行训练，似乎是一种微调的种类。

监督式微调SFT(Supervised Fine Tuning)  
这个方案主要是用人工标注的数据，用传统机器学习中监督学习的方法，对大模型进行微调

基于人类反馈的强化学习微调RLHF(Reinforcement Learning with Human Feedback)  
这个方案的主要特点是把人类的反馈，通过强化学习的方式，引入到对大模型的微调中去，让大模型生成的结果，更加符合人类的一些期望

基于AI反馈的强化学习微调RLAIF(Reinforcement Learning with AI Feedback)  
这个原理大致跟RLHF类似，但是反馈的来源是AI。这里是想解决反馈系统的效率问题，因为收集人类反馈，相对来说成本会比较高、效率比较低

lora微调  
微软发布的微调算法。具体原理看 https://zhuanlan.zhihu.com/p/632159261

Prompt Tuning  
Prompt Tuning的出发点，是基座模型(Foundation Model)的参数不变，为每个特定任务，训练一个少量参数的小模型，在具体执行特定任务的时候按需调用。


### 参考资料

https://zhuanlan.zhihu.com/p/650287173